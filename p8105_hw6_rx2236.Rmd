---
title: "p8105_hw6_rx2236"
author: "Ruiqi Xue"
date: "2023-11-30"
output: github_document
---

```{r message=FALSE}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(purrr)
set.seed(1)

```

## Problem 1

In the data cleaning code below we create a `city_state` variable, change `victim_age` to numeric, modifiy victim_race to have categories white and non-white, with white as the reference category, and create a `resolution` variable indicating whether the homicide is solved. Lastly, we filtered out the following cities: Tulsa, AL; Dallas, TX; Phoenix, AZ; and Kansas City, MO; and we retained only the variables `city_state`, `resolution`, `victim_age`, `victim_sex`, and `victim_race`.

```{r q1_data_cleaning}
homicide_df = 
  read_csv("homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) |> 
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```

Next we fit a logistic regression model using only data from Baltimore, MD. We model `resolved` as the outcome and `victim_age`, `victim_sex`, and `victim_race` as predictors. We save the output as `baltimore_glm` so that we can apply `broom::tidy` to this object and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims.

```{r q1_glm_baltimore}
baltimore_glm = 
  filter(homicide_df, city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

Below, by incorporating `nest()`, `map()`, and `unnest()` into the preceding Baltimore-specific code, we fit a model for each of the cities, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. We show the first 5 rows of the resulting dataframe of model results.

```{r q1_glm_all_cities}
model_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```

Below we generate a plot of the estimated ORs and CIs for each city, ordered by magnitude of the OR from smallest to largest. From this plot we see that most cities have odds ratios that are smaller than 1, suggesting that crimes with male victims have smaller odds of resolution compared to crimes with female victims after adjusting for victim age and race. This disparity is strongest in New yrok. In roughly half of these cities, confidence intervals are narrow and do not contain 1, suggesting a significant difference in resolution rates by sex after adjustment for victim age and race. 

```{r q1_plot}
model_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```



## Problem 2
Import data.
```{r message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Bootstrap.
```{r warning=FALSE}
boot_straps = 
  weather_df |> 
  modelr::bootstrap(n = 5000) |>
  mutate(
    model = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    result1 = map(model, broom::tidy),
    result2 = map(model, broom::glance)) |>
  unnest(result1, result2) |>
  select(.id, term, estimate, r.squared) |>
  pivot_wider(names_from = term, 
              values_from = estimate) |>
  rename(id = ".id",
         r_squared = "r.squared",
         beta_0 = "(Intercept)",
         beta_1 = tmin,
         beta_2 = prcp) |>
  summarize(r_squared, log_beta1_beta2 = log(beta_1*beta_2), log_beta0_beta1 = log(beta_0*beta_1))
  
boot_straps

```

Make plot to show distribution of estimates of r^2.

```{r}
boot_straps |>
  ggplot(aes(x = r_squared)) +
  geom_histogram() +
  labs(title = "Distribution of Estimates of r^2",
       x = "Estimates of r^2",
       y = "Frequency")
  
```

The plot shows that the majority of the estimates of r^2 is greater than 0.9 and around 0.92, which means this model is well-fitted with the data, i.e., the `tmin` and `prcp` are appropriate predictors chosen for the response `tmax`. 

There are `r sum(is.na(boot_straps$log_beta1_beta2))` NA values for the log(β̂1∗β̂2)in the bootstrap samples. 
Apart from the NA values, we have `r sum(!is.na(boot_straps$log_beta1_beta2))` non-NA values. Now we use them to make the plot of distribution of log(β̂1∗β̂2).
```{r}
boot_straps |>
  ggplot(aes(x = log_beta1_beta2)) +
  geom_histogram() +
  labs(title = "Distribution of Estimates of log(beta1*beta2)",
       x = "Estimates of log(beta1*beta2)",
       y = "Frequency")
```

The plot show that the majority of the estimates of log(β̂1∗β̂2) falls around -6, and the distribution is left-skewed.

Now identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r^2 and log(β̂0∗β̂1).
```{r}
r_sq_ci = boot_straps |>
  pull(r_squared) |>
  quantile(probs = c(0.025,0.975))

r_sq_ci


log_beta1_beta2_ci = boot_straps |> 
  pull(log_beta1_beta2) |>
  quantile(probs = c(0.025,0.975), na.rm = TRUE)

log_beta1_beta2_ci

log_beta0_beta1_ci = boot_straps |> 
  pull(log_beta0_beta1) |>
  quantile(probs = c(0.025,0.975))

log_beta0_beta1_ci
```

The 95% CI of r^2 is (`r r_sq_ci[[1]]`, `r r_sq_ci[[2]]`), the 95% CI of log(β̂1∗β̂2) is (`r log_beta1_beta2_ci[[1]]`, `r log_beta1_beta2_ci[[2]]`), and the 95% CI of log(β̂0∗β̂1) is (`r log_beta0_beta1_ci[[1]]`, `r log_beta0_beta1_ci[[2]]`).


## Problem 3

Import and clean data.
```{r warning=FALSE}
birthweight_df = read.csv("birthweight.csv")

birthweight_df = birthweight_df |>
  as.tibble() |>
  janitor::clean_names() |>
  drop_na() |>
  mutate(babysex = factor(case_match(babysex, 1 ~ 'male', 2 ~ 'female')),
         frace = factor(case_match(frace, 1 ~ "White", 2 ~ "Black", 3 ~ "Asian", 4 ~ "Puerto Rican", 8 ~ "Other", 9 ~ "Unknown")),
         malform = factor(case_match(malform, 0 ~ 'absent', 1 ~ 'present')),
         mrace = factor(case_match(mrace, 1 ~ "White", 2 ~ "Black", 3 ~ "Asian", 4 ~ "Puerto Rican", 8 ~ "Other")))

birthweight_df
```

Build a linear regression based on a data-driven model-building process.
```{r}
fit_model = lm(bwt ~ ., data = birthweight_df)
final_model = step(fit_model, trace = 0)

summary(final_model)
```
I first fit a model using all variables and then use the step function to do the automated variable selection (stepwise backward elimination).

Now make a plot of model residuals against fitted values.
```{r message=FALSE}
birthweight_df |>
  add_predictions(final_model) |>
  add_residuals(final_model) |>
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(title = "Residuals Against Fitted Values", 
       x = "Fitted Values", 
       y = "Residuals")
  
```


Now Compare this model to the following two:

1) Using length at birth and gestational age as predictors (main effects only)
```{r}
model1 = lm(bwt ~ blength + gaweeks, data = birthweight_df)

summary(model1)
```

2) Using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
model2 = lm(bwt ~ bhead * blength * babysex, data = birthweight_df)

summary(model2)
```

Make comparisons in terms of the cross-validated prediction error.
```{r}
cv_df = 
  crossv_mc(birthweight_df, 100) |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) |>
  mutate(
    final_mod = map(train, ~final_model),
    mod1  = map(train, ~model1),
    mod2  = map(train, ~model2)) |> 
  mutate(
    rmse_final_model = map2_dbl(final_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model1 = map2_dbl(mod1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model2 = map2_dbl(mod2, test, \(mod, df) rmse(model = mod, data = df)))


cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(title = "Model Comparison In Terms of the Cross-Validated Prediction Error", 
       x = "Model", 
       y = "RMSE")
```

In terms of the cross-validated prediction error, we see from the plot that my model (fitted by stepwise backward elimination) performs better than the other two models, because it has the smallest RMSE in general. Whereas model1 (using length at birth and gestational age as predictors) has the largest RMSE.





